{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3dfddfe4",
   "metadata": {},
   "source": [
    "Исходные данные, промежуточные данные, модели, скрипты находятся по адресу https://drive.google.com/drive/folders/1vXjG7S3HpcbVwiLmWCEvXF_4t7pA2ubE?usp=sharing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f481f468",
   "metadata": {},
   "source": [
    "## 0. Константы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4859da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_vect=100 # Размерность вектора признаков"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "605057ec",
   "metadata": {},
   "source": [
    "## 1. Импорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2920f8-5661-4b82-9a78-573cc78132f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import annoy\n",
    "import codecs\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "from csv import writer\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6661e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\")) # Стоп-слова\n",
    "exclude = set(string.punctuation) # Знаки пунктуации"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d63ffd4",
   "metadata": {},
   "source": [
    "## 2. Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3401799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_txt(line, morpher=morpher, sw=sw):\n",
    "    \"\"\"\n",
    "    Функция формирования нормальной формы слов.\n",
    "        Args:\n",
    "            line(string): текст, \n",
    "            morpher(MorphAnalyzer): класс MorphAnalyzer из библиотеки pymorphy2,\n",
    "            sw(set): множество стоп-слов.\n",
    "        Returns:\n",
    "            spls(list): список слов в нормальной форме.\n",
    "    \"\"\"\n",
    "    spls = \" \".join(i.strip() for i in line.split(',')).split('(')\n",
    "    spls = \" \".join(\" \".join(\" \".join(spls).split(')')).split('.')).split('-')\n",
    "    spls = \" \".join(spls).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i.replace('?', '').replace('!', '') for i in spls if \n",
    "            i not in exclude and i not in sw and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "889e890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(line, model, N_vect=N_vect):\n",
    "    \"\"\"\n",
    "    Функция формирует вектор признаков вопроса.\n",
    "        Args:\n",
    "            line(string): текст, \n",
    "            model(gensim.models): класс models из библиотеки gensim,\n",
    "            N_vect(int): размерность вектора.\n",
    "        Returns:\n",
    "            vector(array): вектор признаков.\n",
    "    \"\"\"\n",
    "    question = preprocess_txt(line)\n",
    "    n_w2v = 0\n",
    "    vector = np.zeros(N_vect)\n",
    "    for word in question:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv[word]\n",
    "            n_w2v += 1\n",
    "    if n_w2v > 0:\n",
    "        vector = vector / n_w2v\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e2dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arr(ser, model, N_vect=N_vect):\n",
    "    \"\"\"\n",
    "    Функция формирует массив векторов признаков для текстов.\n",
    "        Args:\n",
    "            ser(Series): тексты, \n",
    "            model(gensim.models): класс models из библиотеки gensim,\n",
    "            N_vect(int): размерность вектора.\n",
    "        Returns:\n",
    "            arr(array): массив векторов признаков.\n",
    "    \"\"\"\n",
    "    arr = np.zeros([len(ser), N_vect])\n",
    "    i = 0\n",
    "    for line in tqdm(ser.values):\n",
    "        arr[i] = get_vector(line, model, N_vect)\n",
    "        i += 1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2cee517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_set(ser):\n",
    "    \"\"\"\n",
    "    Функция формирует множество слов текстов.\n",
    "        Args:\n",
    "            ser(Series): тексты, \n",
    "        Returns:\n",
    "            sentences_set(array): множество слов текстов.\n",
    "    \"\"\"    \n",
    "    sentences_set = set()\n",
    "    for line in tqdm(ser.values):\n",
    "        spls = set(preprocess_txt(line))\n",
    "        sentences_set.update(spls)\n",
    "    return sentences_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54dd2f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_w2v_model(ser, N_vect=N_vect):\n",
    "    \"\"\"\n",
    "    Функция обучает модель word2vec на всех словах текстов.\n",
    "        Args:\n",
    "            ser(Series): тексты, \n",
    "            N_vect(int): размерность вектора.\n",
    "        Returns:\n",
    "            model(gensim.models): класс models из библиотеки gensim.\n",
    "    \"\"\"\n",
    "    sentences_set = get_words_set(ser)\n",
    "    sentences = [[i] for i in sentences_set]\n",
    "    model = Word2Vec(sentences=sentences, vector_size=N_vect, min_count=1, window=5)\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7b2cc03",
   "metadata": {},
   "source": [
    "## 3. Загрузка данных и сохранение предварительно обработанных данных в файлы"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "274fc6e5",
   "metadata": {},
   "source": [
    "### 3.1 Загрузка продуктовых вопросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f09d14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего продуктовых запросов 35548\n"
     ]
    }
   ],
   "source": [
    "# Загрузим датасет с продуктовыми вопросами\n",
    "prod_df = pd.read_csv('./data/ProductsDataset.csv')\n",
    "# Удалим неиспользуемые признаки\n",
    "prod_df.drop(['category_id', 'subcategory_id', 'properties', 'image_links'], \n",
    "             inplace=True, axis=1)\n",
    "print('Всего продуктовых запросов', len(prod_df)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c9e8adf",
   "metadata": {},
   "source": [
    "### 3.2 Загрузка непродуктовых вопросов для классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d640f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если файл \"nonprod_QA.txt\" с обработанными непродуктовыми \n",
    "# вопросами и ответами уже существует, не выполняем эту ячейку\n",
    "\n",
    "if not os.path.isfile(\"./data/nonprod_QA.txt\"):\n",
    "    # Если файла \"nonprod_QA.txt\" с обработанными продуктовыми нет\n",
    "    # Используем текстовый датасет из ответов mail.ru.\n",
    "    question = None\n",
    "    written = True\n",
    "    i = 0\n",
    "    # Идем по всем записям, берем первую строку как вопрос, после табуляции \n",
    "    # добавляем первый ответ\n",
    "    # Cохраним вопросы в файл \"nonprod_QA.txt\" для экономии времени\n",
    "    with codecs.open(\"./data/nonprod_QA.txt\",\"w\", \"utf-8\") as fout:\n",
    "        with codecs.open(\"./data/Answers.txt\", \"r\", \"utf-8\") as fin:\n",
    "            for line in tqdm(fin):\n",
    "                if line.startswith(\"---\"):\n",
    "                    written = False\n",
    "                    continue\n",
    "                if not written and question is not None:\n",
    "                    fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + \n",
    "                               line.replace(\"\\t\", \" \"))\n",
    "                    i += 1\n",
    "                    written = True\n",
    "                    question = None\n",
    "                    continue\n",
    "                if not written:\n",
    "                    question = line.strip()\n",
    "                    continue\n",
    "                # if i > 350:\n",
    "                #     break\n",
    "    print('Загружено непродуктовых вопросов', i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f631740",
   "metadata": {},
   "source": [
    "Загружено непродуктовых вопросов 1163342"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e0bab8b",
   "metadata": {},
   "source": [
    "## 4. Построение классификатора вопросов"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06cb6a20",
   "metadata": {},
   "source": [
    "### 4.1. Обучение модели word2vec на всех вопросах, продуктовых и непродуктовых."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea53f4eb",
   "metadata": {},
   "source": [
    "Формируем датафрейм продуктовых вопросов и сохраняем в файл *'prod_df.csv'* для дальнейшего использования при поиске похожих товаров по продуктовому вопросу."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35563505",
   "metadata": {},
   "source": [
    "Оставляем в prod_df_to_classify только запросы для классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4af27f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Юбка детская ORBY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ботильоны</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title\n",
       "0  Юбка детская ORBY\n",
       "1          Ботильоны"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_df_to_classify = prod_df.drop(['descrirption', 'product_id'], axis=1)\n",
    "prod_df_to_classify.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3114445a",
   "metadata": {},
   "source": [
    "Составляем nonprod_df_to_classify с непродуктовыми вопросами для классификатора.  \n",
    "Ограничим количество вопросов для обучения классификатора 36000 - примерно по числу продуктовых вопросов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a522ee5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca7a5c578bc445086ef2ebc62fc80c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nonprod_df_to_classify = pd.DataFrame(columns=['title'])\n",
    "i = 0\n",
    "with codecs.open(\"./data/nonprod_QA.txt\",\"r\", \"utf-8\") as fin:\n",
    "    for line in tqdm(fin):\n",
    "        # загружаем только вопросы без ответов\n",
    "        nonprod_df_to_classify.loc[len(nonprod_df_to_classify)] = [line.split('\\t')[0]]\n",
    "        i+=1\n",
    "        if i > 36000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f110b13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вопрос о ТДВ)) давно и хорошо отдыхаем)) ЛИЧНО...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Как парни относятся к цветным линзам? Если у д...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "0  вопрос о ТДВ)) давно и хорошо отдыхаем)) ЛИЧНО...\n",
       "1  Как парни относятся к цветным линзам? Если у д..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonprod_df_to_classify.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80e9e8b6",
   "metadata": {},
   "source": [
    "Удаляем знаки препинания и делаем лемматизацию, обучаем модель word2vec на всех наших вопросах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02bc2310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если файл \"w2v_clsfy.model\" с обученной моделью уже существует,\n",
    "# загружаем обученную модель из файла\n",
    "if os.path.isfile(\"./models/w2v_clsfy.model\"):\n",
    "    model_clsfy = gensim.models.Word2Vec.load(\"./models/w2v_clsfy.model\")\n",
    "\n",
    "# Если файла \"w2v_clsfy.model\" с обученной моделью еще нет\n",
    "else:\n",
    "    # Объединяем вопросы для обучения модели word2vec\n",
    "    classify_df = pd.concat([prod_df_to_classify, nonprod_df_to_classify], \n",
    "                            ignore_index=True)\n",
    "    # Обучим модель word2vec на всех вопросах (Модель классификации, \n",
    "    # обученная на векторах предложений вопросов показала лучшую метрику \n",
    "    # по сравнению с моделью, обученной на множествах слов вопросов. \n",
    "    # Поэтому здесь не используется функция fit_w2v_model)\n",
    "    sentences = []\n",
    "    for line in tqdm(classify_df.title.values):\n",
    "        spls = preprocess_txt(line, morpher, sw)\n",
    "        sentences.append(spls)\n",
    "    sentences = [i for i in sentences if len(i) > 0]\n",
    "    model_clsfy = Word2Vec(sentences=sentences, vector_size=100, min_count=1, window=5)        \n",
    "    # сохраняем обученную модель в файл\n",
    "    model_clsfy.save(\"w2v_clsfy.model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "965a7b81",
   "metadata": {},
   "source": [
    "### 4.2. Формирование массива данных для обучения классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71caf1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если файл \"total_arr.npy\" уже существует,\n",
    "# загружаем из файла\n",
    "if os.path.isfile(\"./data/total_arr.npy\"):\n",
    "    total_arr = np.load('./data/total_arr.npy')\n",
    "else:\n",
    "    # Массив векторов продуктовых вопросов\n",
    "    prod_arr = get_arr(prod_df_to_classify.title, model_clsfy)\n",
    "    # Массив векторов непродуктовых вопросов\n",
    "    nonprod_arr = get_arr(nonprod_df_to_classify.title, model_clsfy)\n",
    "    # Добавляем метки классов\n",
    "    prod_lbl = np.ones([len(prod_df_to_classify), 1])\n",
    "    nonprod_lbl = np.zeros([len(nonprod_df_to_classify), 1])\n",
    "    prod_arr_lbl = np.hstack([prod_arr, prod_lbl])\n",
    "    nonprod_arr_lbl = np.hstack([nonprod_arr, nonprod_lbl])\n",
    "    # Общий массив векторов \n",
    "    total_arr = np.vstack([prod_arr_lbl, nonprod_arr_lbl])\n",
    "    # Загрузим массив в файл для экономии времени\n",
    "    file_name = './data/total_arr.npy'\n",
    "    np.save(file_name, total_arr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d38a0425",
   "metadata": {},
   "source": [
    "### 4.3. Разделение данных на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e168313",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_list = list(range(100))\n",
    "y = total_arr[:,-1]\n",
    "X = total_arr[:, ind_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "959bd34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.789258321126302 3.1210029125213623\n"
     ]
    }
   ],
   "source": [
    "print(X.min(), X.max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b5be5d9",
   "metadata": {},
   "source": [
    "Нормализацию данных можно не проводить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b1f0f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "685881cc",
   "metadata": {},
   "source": [
    "### 4.4. Создание и обучение модели классификатора, расчет метрики accuracy на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaf536e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=200)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression(max_iter=200)\n",
    "lr_model.fit (X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c913302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9414861402282786"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lr_model.predict(X_test)\n",
    "# note that we can use vector operations, because we deal with numpy tensors\n",
    "accuracy = (predictions == y_test).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e561d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели в файл\n",
    "with open('./models/LR_model.pkl', 'wb') as output:\n",
    "    pickle.dump(lr_model, output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa0a145a",
   "metadata": {},
   "source": [
    "После валидации обучим модель на всех данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0b8cc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_full = LogisticRegression(max_iter=300)\n",
    "lr_model_full.fit (X,y)\n",
    "# Сохранение модели в файл\n",
    "with open('./models/LR_model_full.pkl', 'wb') as output:\n",
    "    pickle.dump(lr_model_full, output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c958235",
   "metadata": {},
   "source": [
    "Демонстрация работы классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2185e57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос продуктовый\n"
     ]
    }
   ],
   "source": [
    "line = 'рубашка'\n",
    "quest_label = lr_model_full.predict(get_vector(line, model_clsfy).reshape(1, -1))[0]\n",
    "if quest_label == 1:\n",
    "    print('Вопрос продуктовый')\n",
    "else:\n",
    "    print('Вопрос непродуктовый')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d45af59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9433496389471232"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lr_model_full.predict(X_test)\n",
    "# note that we can use vector operations, because we deal with numpy tensors\n",
    "accuracy = (predictions == y_test).mean()\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "068a7158",
   "metadata": {},
   "source": [
    "## 5. Обработка продуктовых вопросов."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dee35909",
   "metadata": {},
   "source": [
    "### 5.1. Обучение модели word2vec на всех словах продуктовых вопросов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69a478da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если файл \"w2v_prod.model\" с обученной моделью уже существует, \n",
    "# загружаем обученную модель из файла\n",
    "if os.path.isfile(\"./models/w2v_prod.model\"):\n",
    "    model_prod = gensim.models.Word2Vec.load(\"./models/w2v_prod.model\")\n",
    "\n",
    "# Если файла \"w2v_prod.model\" с обученной моделью еще нет\n",
    "# обучаем модель на всех словах продуктовых вопросов\n",
    "else:\n",
    "    \n",
    "    model_prod = fit_w2v_model(prod_df.title)\n",
    "    model_prod.save(\"./models/w2v_prod.model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77693739",
   "metadata": {},
   "source": [
    "### 5.2. Построение индекса продуктовых вопросов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e608ba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_ind = annoy.AnnoyIndex(N_vect ,'angular')\n",
    "# Если файл 'prod_ind.ann' с индексом уже существует,\n",
    "# загружаем его из файла, а также файл словаря index_map.pkl\n",
    "if os.path.isfile(\"./data/prod_ind.ann\"):\n",
    "    prod_ind.load('./data/prod_ind.ann')\n",
    "    with open('./data/index_map.pkl', 'rb') as f:\n",
    "        index_map = pickle.load(f)\n",
    "else:\n",
    "\n",
    "    index_map = {}\n",
    "    counter = 0\n",
    "\n",
    "    for counter in tqdm(range(len(prod_df))):\n",
    "        index_map[counter] = prod_df.iloc[counter].product_id\n",
    "        line = prod_df.iloc[counter].title\n",
    "        vector = get_vector(line, model_prod)\n",
    "        prod_ind.add_item(counter, vector)\n",
    "        counter += 1\n",
    "\n",
    "    prod_ind.build(10)  # The number of trees. More trees gives higher search precision\n",
    "    prod_ind.save('./data/prod_ind.ann')\n",
    "    file_name = './data/index_map.pkl'\n",
    "    with open(file_name, 'wb') as output:\n",
    "        pickle.dump(index_map, output)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14efac9a",
   "metadata": {},
   "source": [
    "### 5.3. Создание метода ответов на продуктовые вопросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0d5daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_prod_answer(question, index_map=index_map, \n",
    "                     model_prod=model_prod): \n",
    "    vector =  get_vector(question, model_prod)\n",
    "    answer_index = prod_ind.get_nns_by_vector(vector, 1)\n",
    "    return index_map[answer_index[0]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51c3bd57",
   "metadata": {},
   "source": [
    "Демонстрация работы метода ответов на продуктовые вопросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fc8bc98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'58e3cfe6132ca50e053f5f82'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_prod_answer('Юбка детская ORBY')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b5d169f",
   "metadata": {},
   "source": [
    "## 6. Обработка непродуктовых вопросов."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd15c399",
   "metadata": {},
   "source": [
    "### 6.1. Загрузка данных и формирование nonprod_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e55aee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если файла 'nonprod_df.csv' не существует, создаем его\n",
    "if not os.path.isfile('./data/nonprod_df.csv'):\n",
    "    nonprod_df = pd.DataFrame(columns=['question', 'answer'])\n",
    "    nonprod_df.to_csv('./data/nonprod_df.csv', index=False)\n",
    "    # Построчно формируем файл 'nonprod_df.csv' из файла nonprod_QA.txt\n",
    "    i=0\n",
    "    with codecs.open(\"./data/nonprod_QA.txt\",\"r\", \"utf-8\") as fin:\n",
    "        for line in tqdm(fin):\n",
    "            try:\n",
    "                # загружаем строку вопрос-ответ\n",
    "                QA_line = [line.split('\\t')[0], line.split('\\t')[1]]\n",
    "                with open('./data/nonprod_df.csv', 'a', newline='') as f_object:\n",
    "                    writer_object = writer(f_object)\n",
    "                    writer_object.writerow(QA_line)\n",
    "                    f_object.close()\n",
    "                    # Индикация прогресса\n",
    "                    if i%10000 == 0:\n",
    "                        print (i)\n",
    "                    i+=1\n",
    "            except:\n",
    "                pass\n",
    "    print('Загружено непродуктовых вопросов-ответов', i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "826ddc53",
   "metadata": {},
   "source": [
    "Загружено непродуктовых вопросов-ответов 1163341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5001f53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вопрос о ТДВ)) давно и хорошо отдыхаем)) ЛИЧНО...</td>\n",
       "      <td>хомячка.... \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Как парни относятся к цветным линзам? Если у д...</td>\n",
       "      <td>меня вобще прикалывает эта тема :). \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Что делать, сегодня нашёл 2 миллиона рублей? .</td>\n",
       "      <td>Если это \"счастье \" действительно на вас свали...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Эбу в двенашке называется Итэлма что за эбу? .</td>\n",
       "      <td>ЭБУ — электронный блок управления двигателем а...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>академия вампиров. сколько на даный момент час...</td>\n",
       "      <td>4. Охотники и Жертвы, Ледяной укус, Поцелуй ть...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  вопрос о ТДВ)) давно и хорошо отдыхаем)) ЛИЧНО...   \n",
       "1  Как парни относятся к цветным линзам? Если у д...   \n",
       "2     Что делать, сегодня нашёл 2 миллиона рублей? .   \n",
       "3     Эбу в двенашке называется Итэлма что за эбу? .   \n",
       "4  академия вампиров. сколько на даный момент час...   \n",
       "\n",
       "                                              answer  \n",
       "0                                     хомячка.... \\n  \n",
       "1             меня вобще прикалывает эта тема :). \\n  \n",
       "2  Если это \"счастье \" действительно на вас свали...  \n",
       "3  ЭБУ — электронный блок управления двигателем а...  \n",
       "4  4. Охотники и Жертвы, Ледяной укус, Поцелуй ть...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем nonprod_df из файла\n",
    "nonprod_df = pd.read_csv('./data/nonprod_df.csv')\n",
    "nonprod_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89f06e09",
   "metadata": {},
   "source": [
    "### 6.2. Формирование множества слов непродуктовых вопросов."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "337b7b71",
   "metadata": {},
   "source": [
    "Ввиду большого объема данных сформировать множество слов непродуктовых запросов на моем компьютере в один заход не получилось. Вопросы, импортированные из таблицы nonprod_df, были разбиты на чанки по 50 тыс. В процессе обработки выяснилось, что размер чанка можно было увеличить в 4 раза.  \n",
    "Формирование чанков производилось скриптом ***get_chunk.py*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2eaa9079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если файлов чанков не существует, формируем их и сохраняем в файлы\n",
    "# На основе данного кода был создан скрипт get_chunk.py,\n",
    "# с помощью которого были созданы файлы чанков\n",
    "if not os.path.isfile(\"./chunks/chunk_0.pkl\"):\n",
    "    chunk_vol = 50000\n",
    "    n_chunks = len(nonprod_df)//50000 + 1\n",
    "    nonprod_word_set = set()\n",
    "    for i in range(n_chunks):\n",
    "        begin = i*chunk_vol\n",
    "        end = min((i+1)*chunk_vol, len(nonprod_df))\n",
    "        # Индикация прогресса выполнения\n",
    "        print(begin,end)\n",
    "        chunk_ser = nonprod_df.question[begin:end]\n",
    "        chunk_word_set = get_words_set(chunk_ser)\n",
    "        file_name = './chunks/chunk_'+str(i)+'.pkl'\n",
    "        with open(file_name, 'wb') as output:\n",
    "            pickle.dump(chunk_word_set, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27ec9ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего слов непродуктовых вопросов 866369\n"
     ]
    }
   ],
   "source": [
    "# Собираем множество слов непродуктовых вопросов из 24 чанков,\n",
    "# ранее записанных в файлы\n",
    "nonprod_set = set()\n",
    "for c in range(24):\n",
    "    file_name = './chunks/chunk_'+str(c)+'.pkl'\n",
    "    with open(file_name, 'rb') as f:\n",
    "        chunk_set = pickle.load(f)\n",
    "    nonprod_set.update(chunk_set)\n",
    "print('Всего слов непродуктовых вопросов',len(nonprod_set))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd7f33de",
   "metadata": {},
   "source": [
    "### 6.3. Обучение модели word2vec на всех словах непродуктовых вопросов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6c0ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если файл \"w2v_nonprod.model\" с обученной моделью уже существует, \n",
    "# загружаем обученную модель из файла\n",
    "if os.path.isfile(\"./models/w2v_nonprod.model\"):\n",
    "    model_nonprod= gensim.models.Word2Vec.load(\"./models/w2v_nonprod.model\")\n",
    "\n",
    "# Если файла \"w2v_nonprod.model\" с обученной моделью еще нет\n",
    "# обучаем модель на всех словах продуктовых вопросов\n",
    "else:\n",
    "    model_nonprod = fit_w2v_model(nonprod_df.question)\n",
    "    # Сохраним модель \n",
    "    # (3 файла: w2v_nonprod.model, w2v_nonprod.model.syn1neg.npy, \n",
    "    # w2v_nonprod.model.wv.vectors.npy )\n",
    "    model_nonprod.save(\"./models/w2v_nonprod.model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bc228fb",
   "metadata": {},
   "source": [
    "### 6.4. Формирование массива векторов непродуктовых вопросов."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "768b8100",
   "metadata": {},
   "source": [
    "Ввиду большого объема данных сформировать индекс непродуктовых запросов на моем компьютере в один заход не получилось. Вопросы, импортированные из таблицы nonprod_df, были разбиты на чанки по 100 тыс, из которых были сформированы массивы векторов признаков и сохранены в файлы.  \n",
    "Формирование массивов векторов производилось скриптом ***nonprod_arr.py***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a1e1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем массив векторов признаков непродуктовых вопросов из файлов\n",
    "n_chunk = 0\n",
    "nonprod_arr = np.load('./arrays/nonprod_arr_'+str(n_chunk)+'.npy')\n",
    "for n_chunk in range(1, 12):\n",
    "    file_name = './arrays/nonprod_arr_'+str(n_chunk)+'.npy'\n",
    "    curr_arr = np.load('./arrays/nonprod_arr_'+str(n_chunk)+'.npy')\n",
    "    nonprod_arr = np.vstack([nonprod_arr, curr_arr])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29f9efc1",
   "metadata": {},
   "source": [
    "### 6.5. Построение индекса непродуктовых вопросов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2fa818e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b955a89758e44dc1a33571d090ff9ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1163341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nonprod_ind = annoy.AnnoyIndex(N_vect ,'angular')\n",
    "# Если файл 'nonprod_ind.ann' с индексом уже существует,\n",
    "# загружаем его из файла, а также файл словаря answer_map\n",
    "if os.path.isfile(\"./data/nonprod_ind.ann\"):\n",
    "    nonprod_ind.load('./data/nonprod_ind.ann')\n",
    "    with open('./data/answer_map.pkl', 'rb') as f:\n",
    "        answer_map = pickle.load(f)\n",
    "    \n",
    "# Если файла 'nonprod_ind.ann' с индексом не существует, \n",
    "# собираем индекс из массива nonprod_arr\n",
    "else:\n",
    "    counter = 0\n",
    "    answer_map = {} # Словарь ответов\n",
    "    for counter in tqdm(range(nonprod_arr.shape[0])):\n",
    "        vector = nonprod_arr[counter]\n",
    "        nonprod_ind.add_item(counter, vector)\n",
    "\n",
    "        answer_map[counter] = nonprod_df.iloc[counter].answer\n",
    "        counter += 1\n",
    "\n",
    "    nonprod_ind.build(10)  # The number of trees. More trees gives higher search precision\n",
    "    nonprod_ind.save('./data/nonprod_ind.ann')\n",
    "    file_name = './data/answer_map.pkl'\n",
    "    with open(file_name, 'wb') as output:\n",
    "        pickle.dump(index_map, output)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "874f6312",
   "metadata": {},
   "source": [
    "### 6.6. Создание метода ответов на непродуктовые вопросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89faa2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nonprod_answer(question, answer_map=answer_map, \n",
    "                        model_nonprod=model_nonprod): \n",
    "    vector =  get_vector(question, model_nonprod)\n",
    "    answer_index = nonprod_ind.get_nns_by_vector(vector, 1)\n",
    "    return answer_map[answer_index[0]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96e5582c",
   "metadata": {},
   "source": [
    "## 7. Создание общего метода ответа на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fffccb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./models/LR_model_full.pkl', 'rb') as f:\n",
    "    lr_model_full = pickle.load(f)\n",
    "\n",
    "def get_answer(question, \n",
    "               lr_model_full=lr_model_full, \n",
    "               model_clsfy=model_clsfy,\n",
    "               model_prod=model_prod, \n",
    "               model_nonprod=model_nonprod,\n",
    "               index_map=index_map, \n",
    "               answer_map=answer_map):\n",
    "    quest_label = lr_model_full.predict(get_vector(question, model_clsfy).reshape(1, -1))[0]\n",
    "    if quest_label == 1:  # Вопрос продуктовый\n",
    "        answer = find_prod_answer(question)\n",
    "    else:                 # Вопрос непродуктовый\n",
    "        answer = find_nonprod_answer(question)\n",
    "    return answer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8edf9cec",
   "metadata": {},
   "source": [
    "## 8. Примеры работы метода get_answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed6122f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "58e3cfe6132ca50e053f5f82"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "line = 'Юбка детская ORBY'\n",
    "display(HTML(get_answer(line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8343841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p> Площадь треугольника<br>s=1/2ah </p>. \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "line = 'чему равна площадь треугольника'\n",
    "display(HTML(get_answer(line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1340f420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Алейкум с добрым !<br>Кстати , из тех же букв можно составить \"Дуры с тромбом\" :). \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "line = 'С добрым утром'\n",
    "display(HTML(get_answer(line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31c667da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Начнем с коньячка. \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "line = 'Хочу выпить'\n",
    "display(HTML(get_answer(line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa6388cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "если твой вес позволяет, если нет, то для настроения все равно поешь. \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "line = 'Хочу поесть'\n",
    "display(HTML(get_answer(line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f14e06ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "ко мне приезжай я накормлю))). \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "line = 'Хочу пожрать'\n",
    "display(HTML(get_answer(line)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
